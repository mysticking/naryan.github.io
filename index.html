<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Naryan Aggarwal</title>
    <link rel="stylesheet" href="style.css">
     <!-- Prism.js CSS -->
     <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
     <!-- Prism.js JavaScript -->
     <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
     <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
     <!-- For formatting the output tables -->
     <style>
        table {
            width: 100%;
            border-collapse: collapse;
        }
        table, th, td {
            border: 1px solid black;
        }
        th, td {
            padding: 8px;
            text-align: center;
        }
        th {
            background-color: #f2f2f2;
        }
    </style>
 
</head>
<body>
    <header>
        <nav id="navbar">
            <a href="#home">Home</a>
            <a href="#about">About</a>
            <a href="#skills">Skills</a>
            <a href="#portfolio">Portfolio</a>
            <a href="">Resume</a>
            <a href="#contact">Contact</a>
        </nav>
    </header>
    <main>
        <section id="home">
            <h1>Naryan Aggarwal</h1>
            <p>Business and Data Analyst Student</p>
            <p>Benedictine University in Lisle</p>
        </section>

        <section id="about">
            <h2>Hello, I'm Naryan Aggarwal,</h2>
            <p>a college senior studying Business Analytics.</p>
            <p>As a graduating college student with a Bachelor's degree in Business Analytics, I am
                eager to apply my analytical and business skills to data-driven decision-making in a
                dynamic corporate environment. With a solid foundation in statistical analysis, data
                visualization, and Python, I am seeking opportunities within the field of business
                analytics. I wish to utilize my knowledge to extract insights from complex datasets,
                ultimately aiming to drive innovation and efficiency. I am excited to embark on a
                career path where I can make an impact by transforming data into valuable
                solutions.</p>
        </section>

        <section id="skills" class="skills-section">
            <h3>My Skills</h3>
            <div class="skills-grid">
                <div class="skill-tile">HTML</div>
                <div class="skill-tile">CSS</div>
                <div class="skill-tile">JavaScript</div>
                <div class="skill-tile">Python</div>
                <div class="skill-tile">Java</div>
                <div class="skill-tile">SQL</div>
            </div>
            <br>
            <div class="skills-grid">
                <div class="skill-tile">C++</div>
                <div class="skill-tile">C#</div>
                <div class="skill-tile">French</div>
                <div class="skill-tile">Unix/Linux</div>
                <div class="skill-tile">Web Scraping</div>
                <div class="skill-tile">Swift</div>
            </div>
        </section>

        <section id="portfolio">
            <p>In progress</p>
        </section>

        <h2>Academic Portfolio</h2>
        <p>I have practiced with many methods of data analytics so far in my course curriculum. Below are some examples
            of my implementations of some classical and "big data" methods. For the classical methods, I have also included
            my Python code so results can be checked and reproduced.
        </p>

        <!--Naive Method-->
        <section class="code-explanation-container">
            <div class="explanation">
                <h3>Naive Method</h3>
                <p>This method is an analysis of a predetermined set of data using the naive method.
                    After generating a simple forecast, the program then calculates errors, absolute
                    errors, and absolute percentage errors. Using that data, the MAPE is calculated.
                    The results are below
                </p>
                <table>
                    <thead>
                        <tr>
                            <th>Actual</th>
                            <th>Forecast</th>
                            <th>Error</th>
                            <th>Absolute Error</th>
                            <th>Absolute % Error</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>92.0</td>
                            <td>NaN</td>
                            <td>NaN</td>
                            <td>NaN</td>
                            <td>NaN</td>
                        </tr>
                        <tr>
                            <td>91.7</td>
                            <td>92.0</td>
                            <td>-0.3</td>
                            <td>0.3</td>
                            <td>0.327154</td>
                        </tr>
                        <tr>
                            <td>91.0</td>
                            <td>91.7</td>
                            <td>-0.7</td>
                            <td>0.7</td>
                            <td>0.769231</td>
                        </tr>
                        <tr>
                            <td>89.0</td>
                            <td>91.0</td>
                            <td>-2.0</td>
                            <td>2.0</td>
                            <td>2.247191</td>
                        </tr>
                        <tr>
                            <td>94.7</td>
                            <td>89.0</td>
                            <td>5.7</td>
                            <td>5.7</td>
                            <td>6.019007</td>
                        </tr>
                        <tr>
                            <td>93.5</td>
                            <td>94.7</td>
                            <td>-1.2</td>
                            <td>1.2</td>
                            <td>1.283422</td>
                        </tr>
                        <tr>
                            <td>90.0</td>
                            <td>93.5</td>
                            <td>-3.5</td>
                            <td>3.5</td>
                            <td>3.888889</td>
                        </tr>
                        <tr>
                            <td>89.8</td>
                            <td>90.0</td>
                            <td>-0.2</td>
                            <td>0.2</td>
                            <td>0.222717</td>
                        </tr>
                        <tr>
                            <td>91.2</td>
                            <td>89.8</td>
                            <td>1.4</td>
                            <td>1.4</td>
                            <td>1.535088</td>
                        </tr>
                        <tr>
                            <td>87.2</td>
                            <td>91.2</td>
                            <td>-4.0</td>
                            <td>4.0</td>
                            <td>4.587156</td>
                        </tr>
                        <tr>
                            <td>93.8</td>
                            <td>87.2</td>
                            <td>6.6</td>
                            <td>6.6</td>
                            <td>7.036247</td>
                        </tr>
                        <tr>
                            <td>98.2</td>
                            <td>93.8</td>
                            <td>4.4</td>
                            <td>4.4</td>
                            <td>4.480652</td>
                        </tr>
                        <tr>
                            <td>NaN</td>
                            <td>98.2</td>
                            <td>NaN</td>
                            <td>NaN</td>
                            <td>NaN</td>
                        </tr>
                    </tbody>
                </table>
                <p>MAPE: 2.9451594710015985</p>
            </div>
            <div class="code">
                <pre><code class="language-python">
import numpy as np
import pandas as pd

"""Here we type the UMICS data directly (We are entering the data directly for simplicity.)"""

# The UMICS data
actual = pd.Series([92.0, 91.7, 91.0, 89.0, 94.7, 93.5, 90.0, 89.8, 91.2, 87.2, 93.8, 98.2])

forecast = pd.Series(np.ones(len(actual) + 1))                          # Create the column for the forecast
forecast[0] = float("NaN") # No forecast here

# Run the indented commands repeatedly, with the value of `i` ranging from 1 to `actual.size`
for i in range(1, len(actual)+1):
    forecast[i] = actual[i - 1]                                         # Use the naive method to create the forecast

df = pd.DataFrame(data = {"Actual": actual, "Forecast": forecast})      # Create a DataFrame (like a spreadsheet)
# Print the DataFrame
print(df)

error = df["Actual"] - df["Forecast"]                                   # The error column
absError = abs(error)                                                   # The absolute error column
absPctError = absError/df["Actual"] * 100                               # The absolute percentage error column
mape = absPctError.mean()                                               # Find the mean absolute percentage error

# Append the error, absolute error, and absolute percentage error columns to the DataFrame `df`
df = pd.DataFrame(data = {**df, "Error": error, "Absolute Error": absError, "Absolute % Error": absPctError })
# Print a formatted string (put Python variable names inside of `{}`)
print(f"{df}\n\nMAPE: {mape}")
                    </code>
                </pre>
            </div>
        </section>

        <hr>

        <!--Causal Regression Method-->
        <section class="code-explanation-container">
            <div class="explanation">
                <h3>Causal Regression</h3>
                <p>Does a causal regression (Ordinary Least Squares) of sandwich sales on the basis of ketchup and mustard prices.
                    Fit is calculated using the first 52 weeks. Then an additional four weeks are simulated to test the accuracy 
                    of the model.
                </p>
                <p>Results are listed below.</p>
                <section id="ols-results">
                    <div class="ols-container">
                        <table class="ols-table">
                            <tbody>
                                <tr>
                                    <td>Dep. Variable:</td>
                                    <td>Sandwich Sales</td>
                                </tr>
                                <tr>
                                    <td>R-squared:</td>
                                    <td>0.971</td>
                                </tr>
                                <tr>
                                    <td>Model:</td>
                                    <td>OLS</td>
                                </tr>
                                <tr>
                                    <td>Adj. R-squared:</td>
                                    <td>0.970</td>
                                </tr>
                                <tr>
                                    <td>Method:</td>
                                    <td>Least Squares</td>
                                </tr>
                                <tr>
                                    <td>F-statistic:</td>
                                    <td>899.1</td>
                                </tr>
                                <tr>
                                    <td>Date:</td>
                                    <td>Fri, 24 May 2024</td>
                                </tr>
                                <tr>
                                    <td>Prob (F-statistic):</td>
                                    <td>1.28e-41</td>
                                </tr>
                                <tr>
                                    <td>Time:</td>
                                    <td>18:05:23</td>
                                </tr>
                                <tr>
                                    <td>Log-Likelihood:</td>
                                    <td>305.56</td>
                                </tr>
                                <tr>
                                    <td>No. Observations:</td>
                                    <td>56</td>
                                </tr>
                                <tr>
                                    <td>AIC:</td>
                                    <td>-605.1</td>
                                </tr>
                                <tr>
                                    <td>Df Residuals:</td>
                                    <td>53</td>
                                </tr>
                                <tr>
                                    <td>BIC:</td>
                                    <td>-599.0</td>
                                </tr>
                                <tr>
                                    <td>Df Model:</td>
                                    <td>2</td>
                                </tr>
                                <tr>
                                    <td>Covariance Type:</td>
                                    <td>nonrobust</td>
                                </tr>
                            </tbody>
                            <thead>
                                <tr>
                                    <th colspan="2">Coefficients</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>const</td>
                                    <td>coef: 5.0007, std err: 0.004, t: 1374.715, P>|t|: 0.000, [0.025: 4.993, 0.975: 5.008]</td>
                                </tr>
                                <tr>
                                    <td>Ketchup Prices</td>
                                    <td>coef: 0.0160, std err: 0.009, t: 1.820, P>|t|: 0.074, [0.025: -0.002, 0.975: 0.034]</td>
                                </tr>
                                <tr>
                                    <td>Mustard Prices</td>
                                    <td>coef: 0.0387, std err: 0.005, t: 8.438, P>|t|: 0.000, [0.025: 0.030, 0.975: 0.048]</td>
                                </tr>
                            </tbody>
                            <thead>
                                <tr>
                                    <th colspan="2">Diagnostics</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>Omnibus:</td>
                                    <td>4.707</td>
                                </tr>
                                <tr>
                                    <td>Prob(Omnibus):</td>
                                    <td>0.095</td>
                                </tr>
                                <tr>
                                    <td>Durbin-Watson:</td>
                                    <td>1.532</td>
                                </tr>
                                <tr>
                                    <td>Jarque-Bera (JB):</td>
                                    <td>4.090</td>
                                </tr>
                                <tr>
                                    <td>Skew:</td>
                                    <td>0.659</td>
                                </tr>
                                <tr>
                                    <td>Prob(JB):</td>
                                    <td>0.129</td>
                                </tr>
                                <tr>
                                    <td>Kurtosis:</td>
                                    <td>3.121</td>
                                </tr>
                                <tr>
                                    <td>Cond. No.:</td>
                                    <td>235</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </section>
                <p>To consider the results:</p>
                <ol>
                    <li>Coefficients: The intercept of the model is very close to the true intercept of the simulation.
                        In addition, the Mustard Price coefficient indicates a strong statistical significance. 
                        This is further confirmed by the low p-value.</li>
                    <li>R-Squared: The high value of the R-squared statistic indicates good fit by strong capture of the
                        variance within the data.
                    </li>
                    <li>F-stat: A very high F-statistic with a near-zero p-value indicates 
                        that the model is statistically significant.</li>
                    <li>The estimates are indicated to be rather precise with the small standard errors.</li>
                    <li>Diagnostic Tests
                        <ul>
                            <li>Durbin-Watson: indicates a small degree of positive autocorrelation.</li>
                            <li>Omnibus, Jarque-Bera, Skew, and Kurtosis: the residuals might not be perfectly normally distributed.</li>
                        </ul>
                    </li>
                </ol>
                <p>Overall, the model is a relatively good fit, with notes that there may be a small degree of influence on
                    future performance based on past sales prices (small positive autocorrelation). It should be noted as well that
                    this model does possess minor issues with residual normality and the previously mentioned autocorrelation.
                </p>
            </div>
            <div class="code">
                <pre><code class="language-python">
import numpy as np
from numpy.random import default_rng
from pandas import Series, concat
import statsmodels.api as sm

# Helpful in reproducing results
random_seed_id = 42

def simulate_topping_prices(topping="Ketchup", intercept=1.00, slope=0.042, sigma=0.021, num_weeks=56, rng=None):
    if rng == None:
        rng = default_rng()
    epsilons = rng.normal(loc=0, scale=sigma, size=num_weeks)
    times = np.arange(num_weeks)
    prices = intercept + slope * times + epsilons
    return Series(prices, name=f"{topping} Prices")

def simulate_sandwich_sales(ketchup_prices, mustard_prices, intercept=5.00, coeff_ketchup=0.021, coeff_mustard=0.036, sigma=0.001, rng=None):
    if rng == None:
        rng = default_rng()
    if len(ketchup_prices) != len(mustard_prices):
        return None
    epsilons = rng.normal(loc=0, scale=sigma, size=len(ketchup_prices))
    sales = intercept + coeff_ketchup * ketchup_prices + coeff_mustard * mustard_prices + epsilons
    return Series(sales, name="Sandwich Sales")

rng=default_rng(seed=random_seed_id)
ketchup_prices = simulate_topping_prices(topping="Ketchup", intercept=1.50, slope=0.004, sigma=0.02, rng=rng)
mustard_prices = simulate_topping_prices(topping="Mustard", intercept=2.50, slope=0.008, sigma=0.01, rng=rng)
sandwich_sales = simulate_sandwich_sales(ketchup_prices, mustard_prices, rng=rng)
data=concat([sandwich_sales, ketchup_prices, mustard_prices], axis="columns")

prices_data = data[["Ketchup Prices", "Mustard Prices"]]
print(prices_data.head())

x = sm.add_constant(data[["Ketchup Prices", "Mustard Prices"]])
y = data["Sandwich Sales"]
model = sm.OLS(y, x)
fit = model.fit()
print(fit.summary())

print("The `x` values")
print(x.head())
print("The `y` values")
print(y.head())
                </code></pre>
            </div>
        </section>

        <hr>

        <!--ARIMA Method-->
        <section class="code-explanation-container">
            <div class="explanation">
                <h3>ARIMA (Autoregressive Integrated Moving Average)</h3>
                <p>This program performs a time series analysis using the ARIMA method on housing data sourced directly from 
                    the US Census Bureau. The data is read from an excel file and indexed by month. The last 24 points
                    are reserved for testing.
                </p>
                <div class="carousel">
                    <div class="carousel-content">
                        <div class="carousel-item">
                            <h4>Exploratory Plot</h4>
                            <img src="images/Portfolio/ARIMA_exploratory_plot.png" alt="Exploratory Plot">
                        </div>
                        <div class="carousel-item">
                            <h4>Autocorrelation Plot</h4>
                            <img src="images/Portfolio/ARIMA_autocorrelation_plot.png" alt="Autocorrelation Plot">
                        </div>
                        <div class="carousel-item">
                            <h4>Partial Autocorrelation Plot</h4>
                            <img src="images/Portfolio/ARIMA_partialcorrelation_plot.png" alt="Partial Autocorrelation Plot">
                        </div>
                        <div class="carousel-item">
                            <h4>ARIMA Model Plot</h4>
                            <img src="images/Portfolio/ARIMA_model_plot.png" alt="Arima Model">
                        </div>
                        
                    </div>
                    <button class="carousel-button prev"><</button>
                    <button class="carousel-button next">></button>
                </div>
                <div>
                    <h4>SARIMAX Results</h4>
                    <table>
                        <thead>
                            <tr>
                                <th colspan="2">Dep. Variable:</th>
                                <td colspan="4">PHS</td>
                            </tr>
                            <tr>
                                <th colspan="2">No. Observations:</th>
                                <td colspan="4">756</td>
                            </tr>
                            <tr>
                                <th colspan="2">Model:</th>
                                <td colspan="4">ARIMA(1, 1, 1)</td>
                            </tr>
                            <tr>
                                <th colspan="2">Log Likelihood:</th>
                                <td colspan="4">-4610.091</td>
                            </tr>
                            <tr>
                                <th colspan="2">Date:</th>
                                <td colspan="4">Fri, 24 May 2024</td>
                            </tr>
                            <tr>
                                <th colspan="2">AIC:</th>
                                <td colspan="4">9226.181</td>
                            </tr>
                            <tr>
                                <th colspan="2">Time:</th>
                                <td colspan="4">20:50:07</td>
                            </tr>
                            <tr>
                                <th colspan="2">BIC:</th>
                                <td colspan="4">9240.061</td>
                            </tr>
                            <tr>
                                <th colspan="2">Sample:</th>
                                <td colspan="4">01-01-1959 - 12-01-2021</td>
                            </tr>
                            <tr>
                                <th colspan="2">HQIC:</th>
                                <td colspan="4">9231.528</td>
                            </tr>
                            <tr>
                                <th colspan="2">Covariance Type:</th>
                                <td colspan="4">opg</td>
                            </tr>
                        </thead>
                    </table>
            
                    <h3>Parameter Estimates</h3>
                    <table>
                        <thead>
                            <tr>
                                <th>Variable</th>
                                <th>Coefficient</th>
                                <th>Std. Error</th>
                                <th>z</th>
                                <th>P>|z|</th>
                                <th>[0.025</th>
                                <th>0.975]</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>ar.L1</td>
                                <td>-0.0273</td>
                                <td>0.093</td>
                                <td>-0.295</td>
                                <td>0.768</td>
                                <td>-0.209</td>
                                <td>0.154</td>
                            </tr>
                            <tr>
                                <td>ma.L1</td>
                                <td>-0.3161</td>
                                <td>0.088</td>
                                <td>-3.604</td>
                                <td>0.000</td>
                                <td>-0.488</td>
                                <td>-0.144</td>
                            </tr>
                            <tr>
                                <td>sigma2</td>
                                <td>1.18e+04</td>
                                <td>467.224</td>
                                <td>25.254</td>
                                <td>0.000</td>
                                <td>1.09e+04</td>
                                <td>1.27e+04</td>
                            </tr>
                        </tbody>
                    </table>
            
                    <h3>Diagnostic Tests</h3>
                    <table>
                        <tbody>
                            <tr>
                                <td>Ljung-Box (L1) (Q):</td>
                                <td>0.00</td>
                            </tr>
                            <tr>
                                <td>Prob(Q):</td>
                                <td>0.98</td>
                            </tr>
                            <tr>
                                <td>Jarque-Bera (JB):</td>
                                <td>81.01</td>
                            </tr>
                            <tr>
                                <td>Prob(JB):</td>
                                <td>0.00</td>
                            </tr>
                            <tr>
                                <td>Heteroskedasticity (H):</td>
                                <td>0.63</td>
                            </tr>
                            <tr>
                                <td>Prob(H) (two-sided):</td>
                                <td>0.00</td>
                            </tr>
                            <tr>
                                <td>Skew:</td>
                                <td>-0.29</td>
                            </tr>
                            <tr>
                                <td>Kurtosis:</td>
                                <td>4.50</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                <p>Conclusions on the results:</p>
                <ol>
                    <li><b>Goodness of Fit:</b> The various criterion (AIC, BIC, and HQIC) are indicative of a better model.
                    The model appears to fit well from the data based on these metrics.</li>
                    <li><b>Coefficients:</b> Though the autoregressive term is not significant, the Moving Average term
                    suggests it is a very important part of the model.</li>
                    <li><b>Variance:</b> It should be noted that variance, however, is quite 
                        high, which suggests the model does not cover much of the variance in the data.</li>
                    <li><b>Ljung-Box Test</b> <i>(Diagnostic Test)</i><b>:</b> Suggests low autocorrelation, which 
                    is great for an ARIMA model.</li>
                    <li><b>Jarque-Bera Test</b> <i>(Diagnostic Test)</i><b>:</b> Residuals are not normally distributed,
                    meaning that forecasts using this model may not be evenly reliable.</li>
                    <li><b>Heteroskedasticity Test</b> <i>(Diagnostic Test)</i><b>:</b> Building upon the previous test, 
                    this value suggests that the residuals' variance is inconsistent, which can affect the model's ability 
                    to perform.</li>
                    <li><b>Skewness and Kurtosis Test</b> <i>(Diagnostic Test)</i><b>:</b> Negative skewness indicates that 
                        the residuals are skewed to the left. A kurtosis value greater than 3 indicates heavier tails than 
                        a normal distribution, suggesting outliers.</li>
                </ol>
                <p>What we can gather from this overall is that, although the model seems to encapsulate the data well, it is 
                    highly likely to falter in its current state if used for forecasting or actual business decisions. Some 
                    improvements can be made that can assist in fortifying the model.
                </p>
                <ul>
                    <li>Adding additional predictors could address the model not normally covering the patterns in the data.</li>
                    <li>Removing the AR term could prove fruitful  as it is seems to be unnecessary. This would also make the 
                        model easier to understand if it is not needed.
                    </li>
                    <li>As data is gathered from a real source, outliers or possibly structural changes in the data source will 
                        affect the results.
                    </li>
                </ul>
            </div>
            <div class="code">
                <pre><code class="language-python">
from pandas import DataFrame, read_excel, concat
from matplotlib import pyplot as plt
from statsmodels.tsa.api import acf, pacf, ARIMA, arma_order_select_ic

def correlogramAsDataFrame(correlogram, partial=False):
    # Find the correlogram with confidence intervals for each lag
    if partial:
        label="PACF"
    else:
        label="ACF"
    vals, confints = correlogram
    # Separate the lower bounds and upper bounds of the confidence intervals
    lower = confints.take(indices=0, axis=1)
    upper = confints.take(indices=1, axis=1)

    # Print the correlogram in text form for preciser reading
    return DataFrame({label: vals, "Lower": lower, "Upper": upper})

def plotCorrelogram(correlogram):
    # Plot the correlogram with the confidence intervals for each lag
    plt.plot(correlogram.iloc[:,0], color="gray", label=correlogram.columns[0])
    plt.plot(correlogram[["Lower"]], color="black", linestyle="dashed", label="Lower")
    plt.plot(correlogram[["Upper"]], color="black", linestyle="dotted", label="Upper")
    plt.legend()
    plt.show()

def diffSeries(series):
    return [series[i+1]-series[i] for i in range(len(series) - 1)]

# Access the data set; `sheet_name=None` means import all sheets from the workbook.
data=read_excel("https://www.census.gov/construction/nrc/xls/starts_cust.xlsx", sheet_name=None, header=[5, 5, 5, 5])

# Extract rows 0 to 779 and columns 0 to 1 from the "Seasonally Adjusted" sheet.
df = data["Seasonally Adjusted"].iloc[0:780, 0:2]
# Update the column headers
df.columns = ["Month", "PHS"]
# Get the phs `Series` by itself
phs = df["PHS"]
# Label the rows of `phs` by the month
phs.index = df["Month"]

# Do an initial exploratory plot
plt.plot(phs)
plt.show()

# Find and display the autocorrelation function.
correlAcf = acf(phs, nlags=10, alpha=0.05)
acfDF = correlogramAsDataFrame(correlAcf)
plotCorrelogram(acfDF)

# Find and display the partial autocorrelation function.
correlPacf = pacf(phs, nlags=10, alpha=0.05)
pacfDF = correlogramAsDataFrame(correlPacf, partial=True)
plotCorrelogram(pacfDF)

# Order selection
p = 1
d = 1
q = 2
model = ARIMA(phs, order=(p, d, q))
fitted_model = model.fit()
print(fitted_model.summary())

# Use AIC/BIC to determine the model order
print(arma_order_select_ic(diffSeries(phs), max_ar=3, max_ma=5, ic=["aic", "bic"]))

# Use the last `holdout` months as the out-of-sample holdout/validation data set
holdout = 24
train_phs = phs[:-holdout]
test_phs = phs[-holdout:]

# Use the `train_phs` data to fit an ARIMA model.
p = 1
d = 1
q = 1
pre_model_train = ARIMA(train_phs, order=(p, d, q), freq="MS")
model_train = pre_model_train.fit()

# Forecast the values for the times in `test_phs` using the `train_phs` data
forecast = model_train.forecast(steps=holdout)
forecast.name = "Forecast"

# Define a convenience function to find the MAPE error metric
def mape(forecast, actual):
    return (abs(actual - forecast)/actual).mean()

# Find the MAPE values
mape_train = mape(model_train.fittedvalues, train_phs)
mape_test = mape(forecast, test_phs)

# Create a `DataFrame` with the actual values and the forecasted values for the holdout
validate_phs = concat([test_phs, forecast], axis="columns")

# Print the holdout `DataFrame` and the MAPE for both the training and testin data
print("Actual and forecasted PHS:")
print(validate_phs, '\n')
print("MAPE for the training data:", mape_train)
print("MAPE for the testing data:", mape_test, '\n')

# Plot the actual data, fitted values (estimated from `train_phs`), and forecasted values (over the holdout)
plt.plot(phs, color="gray", label="Actual")
plt.plot(model_train.fittedvalues, color="black", linestyle="dashed", label="Fitted")
plt.plot(forecast, color="black", linestyle="dotted", label="Forecasted")
plt.legend()
plt.show()

# Print the summary of the fitted model (including the values of the smoothing constants)
print(model_train.summary())
                </code></pre>
            </div>
        </section>

        <section id="contact">
            <h2>Contact Me</h2>
            <form action="submit_form.php" method="post">
                <label for="name">Name:</label>
                <input type="text" id="name" name="name" required>
                
                <label for="email">Email:</label>
                <input type="email" id="email" name="email" required>
                
                <label for="message">Message:</label>
                <textarea id="message" name="message" required></textarea>
                
                <button type="submit">Send</button>
            </form>
            <p>Or reach me at <a href="mailto:naryantaggarwal@gmail.com">naryantaggarwal@gmail.com</a></p>
        </section>
    </main>

    <footer>
        <p>&copy; 2024 Naryan Aggarwal. All rights reserved.</p>
    </footer>

    <script src="script.js"></script>

</body>
</html>
